# STAMNet: A Spatiotemporal Attention Module and Neural Network for Upscaling Reactive Transport Simulations

This repository contains all the code necessary to replicate the experiments described in the paper "STAMNet - A Spatiotemporal Attention Module and Network for Upscaling Reactive Transport Simulations of the Hyporheic Zone." The provided notebooks cover the entire workflow—from data generation and simulation input preparation to surrogate model training and evaluation—offering a streamlined approach to upscale and upsample highly detailed reactive transport (RT) simulations.

## Repository Overview

- **Data Generation:**  
  Notebooks such as `gstools_perm_clean.ipynb` and `gstools_perm_field.ipynb` are used to generate heterogeneous permeability fields. These notebooks employ Gaussian random field generation (using the `gstools` package) to produce realistic permeability maps for subsurface simulations.

- **Input File Preparation:**  
  The `format_input_files.ipynb` notebook automates the creation and modification of PFLOTRAN simulation input files. It systematically adjusts simulation parameters (e.g., permeability correlation lengths, diffusion coefficients) to generate a diverse set of training and testing scenarios, which are essential for sensitivity analyses and robust data generation.

- **PFLOTRAN Simulations and Data Extraction:**  
  Notebooks such as `pflotran_save_patches.ipynb` (and its variant) handle the simulation outputs generated by PFLOTRAN. These scripts:
  - Read simulation output files (typically in `.pt` format).
  - Extract and patch parts of the simulation data.
  - Preprocess the data for training surrogate models or conducting patch-based analyses.

- **Surrogate Model Training & Evaluation:**  
  The core notebooks, `STAMNet_upscaling_clean.ipynb` and `STAMNet_upscaling_all_code.ipynb`, implement the training and testing workflows for various surrogate models:
  - **Baseline MLP:** Provides about a 30× speedup over conventional multiphysics RT simulations while achieving approximately 90% R² performance.
  - **Channel-Attention Augmented MLP:** Enhances the baseline model by reducing the mean average error.
  - **Spatiotemporal Attention Module (STAM):** Introduces a novel attention mechanism that further improves both the mean squared error and R² (up to 92.5%).
  - **STAM-Based 2D Upsampling:** Applies the STAM architecture to perform 2× upsampling in both spatial dimensions, converting coarse simulation outputs into fine-grained predictions with up to 99.9% R².

## Workflow Summary

1. **Permeability Field Generation:**  
   - Use `gstools_perm_clean.ipynb` and `gstools_perm_field.ipynb` to generate heterogeneous permeability maps.
   - Save outputs in CSV/H5 formats to serve as inputs for subsequent PFLOTRAN simulations.

2. **Input File Creation:**  
   - Execute `format_input_files.ipynb` to generate PFLOTRAN input files with varying simulation parameters for both sensitivity analysis and dataset generation.

3. **PFLOTRAN Simulations:**  
   - Run simulations using the generated input files (often via scripts or `mpirun`), resulting in high-fidelity simulation outputs stored in formats (e.g., .pt files) that facilitate post-processing.

4. **Model Training & Testing:**  
   - Train surrogate models using the STAMNet notebooks, where coarse simulation outputs serve as inputs and high-resolution outputs are used as targets.
   - Evaluate model performance using metrics such as mean squared error and R², following the improvements reported in the paper.

5. **Data Post-Processing & Visualization:**  
   - Use patch-based extraction and plotting routines provided in notebooks like `pflotran_save_patches.ipynb` to visually compare surrogate predictions against ground truth and highlight the performance advantages of the attention mechanisms.

## Additional Notes

- **Reproducibility:**  
  All provided scripts and notebooks are designed for reproducibility. For access to the simulation data used in training, please contact Marc Berghouse at marc.berghouse@gmail.com.

- **Experimental Exploration:**  
  Certain notebooks (e.g., those exploring patch-based models) represent additional experimentations and are included for reference, although they were not featured in the final paper.

## Contact

For further inquiries or additional information on the dataset and simulation parameters, please reach out to Marc Berghouse (marc.berghouse@gmail.com).

---

This repository provides a complete workflow for efficient upscaling and upsampling of reactive transport simulations. By integrating advanced neural network architectures and attention mechanisms, it offers a powerful alternative to conventional multiphysics simulations, significantly reducing computational expense while retaining high predictive accuracy.